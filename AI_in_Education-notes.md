<h1>AI in Education</h1>

**Contents**

* [References](#references)
* [The AI Education Movement: Youth, Schools, and Everyone Else](#the-ai-education-movement-youth-schools-and-everyone-else)

---

<h2>References</h2>




* Oregon Department of Education: Generative Artificial Intelligence (AI) in K-12 classrooms
    * https://www.oregon.gov/ode/educator-resources/teachingcontent/Documents/ODE_Generative_Artificial_Intelligence_(AI)_in_K-12_Classrooms_2023.pdf
* Encode Justice: What we do
    * Includes a very long list of references to other sites and material.
    * https://encodejustice.org/#what-we-do
* Student Privacy Compass
    * https://studentprivacycompass.org/introducingspc/
* TeachAI
    * "Empowering educators to teach with and _about_ AI."
    * https://www.teachai.org/
    * AI Guidance For Schools Toolkit
        * https://www.teachai.org/toolkit

<h2>The AI Education Movement: Youth, Schools, and Everyone Else</h2>


2024-01-30

Chris, Organizer, Portland's Techno-Activism Meetup

Maansi Singh, Sahana Srinivasan, and Julianne Huang from Encode Justice Oregon.

<h3>Abstract</h3>


Artificial Intelligence, or AI, is currently in the news almost every day — chatbots like ChatGPT, image generators like Dall-E, and a host of other tools are now available and being put to use in a variety of ways.

While these software algorithms can potentially help us to work faster and smarter, there are many issues to consider in whether and how to implement them. Details that must be addressed include: What data is being used to train the language models? Who owns the source data and the outputs that are generated? How accurate are the models? How much human oversight of the model-building process is there? And what are the potential harms when things go wrong?

These algorithms are already being used to make decisions about people’s lives, like whether a person gets a job or a bank loan and how much time a person convicted of a crime might spend in jail, but students in particular are having their lives and actions analyzed more and more every day. For instance, proctoring software tries to determine whether students are cheating on exams, other software looks for plagiarism in student essays and reports, and there’s even software that analyzes emotions and/or physical objects — Is the student happy or angry? Are they holding a cellphone or a gun?

This month, leaders from Encode Justice Oregon — Maansi Singh, Sahana Srinivasan, and Julianne Huang — will join us to share their experiences and their work on drafting policy recommendations for use of AI in schools. They’ll speak about their concerns and how they think these technologies should be used in educational settings. They'll also discuss the upcoming Youth Citizens Assembly, which will give students an opportunity to add their voices to the digital privacy conversation and pitch their own ideas.

<h3>Notes</h3>


Examples of AI use in education



* Making predictions: e.g. Oregon EIIS identifies students at risk of not graduating.
* Deep Learning Models: e.g. image/speech recognition with Duolingo.
* Virtual chatbots and assistants: e.g. ChatGPT/Khanmigo.
* NLP: e.g. Grammarly.

Administrators



* Adaptive Technology: specialized for each individual.
* School Management: budgeting, scheduling, student transcripts.

Study tools for students



* Speechify
* Quizlet's Q-Chat
* Speaker Coach by Microsoft

Bias



* Group Attribution BIas: generalization from someone sampled who is not representative of the overall population.
* Selection Bias: distribution of sample does not represent distribution of entire population.
* Negative Attributes/Behaviors towards specific ethnicities/genders.
* Can affect:
    * Admissions
    * Sports Recruitment

Negative impacts of algorithms on learning process



* overdependence
    * rely too heavily on AI tools
    * reduces motivation to think independently
* reduced human interaction
* potential for errors

Who is involved in this conversation?



* students, parents, faculty
* We are concerned about the corporations from which systems are sourced.

How to make these tools safer and more effective?



* currently: human supervision
* Use platforms that have been designed for school
    * e.g. Quizlet, Duolingo are transparent about collection, storage, and use of data.
* Teachers need sufficient knowledge about AI
    * They need to understand responsible/ethical usage of AI.

Oregon Chapter



* AI Education Policy Proposal + DOE Collaboration
* AI Ethics Social Justice Week at Jesuit High School
    * School admin participated in a conference to discuss Jesuit education + AI held in North Carolina.
    * Cataloged AI novels in the library: e.g. System Error, Atlas of AI, ...
    * Encode Justice Club at the school
* future: Youth Citizens Assembly

Q&A



* Who are members of the Oregon chapter? students mainly.
* Can students opt out of a specific technology? Yes.
* Good summary of technology. Do they have any experience implementing AI systems? Yes, some classroom experience with AI projects.
